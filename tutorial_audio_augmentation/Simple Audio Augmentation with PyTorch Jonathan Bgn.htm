<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Simple Audio Augmentation with PyTorch | Jonathan Bgn</title>
<meta name="generator" content="Jekyll v3.9.0">
<meta property="og:title" content="Simple Audio Augmentation with PyTorch">
<meta name="author" content="Jonathan Boigne">
<meta property="og:locale" content="en_US">
<meta name="description" content="No matter if you are training a model for automatic speech recognition or something more esoteric like recognizing birds from sound, you could benefit a lot from audio data augmentation. The idea is simple: by applying random transformations to your training examples, you can generate new examples for free and make your training dataset bigger.">
<meta property="og:description" content="No matter if you are training a model for automatic speech recognition or something more esoteric like recognizing birds from sound, you could benefit a lot from audio data augmentation. The idea is simple: by applying random transformations to your training examples, you can generate new examples for free and make your training dataset bigger.">
<link rel="canonical" href="https://jonathanbgn.com/2021/08/30/audio-augmentation.html">
<meta property="og:url" content="https://jonathanbgn.com/2021/08/30/audio-augmentation.html">
<meta property="og:site_name" content="Jonathan Bgn">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2021-08-30T12:00:00+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Simple Audio Augmentation with PyTorch">
<script async="" src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/google-analytics_analytics.js"></script><script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jonathan Boigne"},"dateModified":"2021-08-30T12:00:00+00:00","datePublished":"2021-08-30T12:00:00+00:00","description":"No matter if you are training a model for automatic speech recognition or something more esoteric like recognizing birds from sound, you could benefit a lot from audio data augmentation. The idea is simple: by applying random transformations to your training examples, you can generate new examples for free and make your training dataset bigger.","headline":"Simple Audio Augmentation with PyTorch","mainEntityOfPage":{"@type":"WebPage","@id":"https://jonathanbgn.com/2021/08/30/audio-augmentation.html"},"url":"https://jonathanbgn.com/2021/08/30/audio-augmentation.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" type="image/svg+xml" href="https://jonathanbgn.com/assets/favicon.svg">
  <link rel="stylesheet" href="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/main.css">

  <link rel="preconnect" href="https://fonts.googleapis.com/"> 
  <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin=""> 
  <link href="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/css2.css" rel="stylesheet"><link type="application/atom+xml" rel="alternate" href="https://jonathanbgn.com/feed.xml" title="Jonathan Bgn"><!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/google-analytics_analytics_002.js"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Q73H8CQX17');
</script>

<!-- Previous analytics.js used by Universal Analytics -->
<script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-156522905-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script type="text/javascript" id="MathJax-script" async="" src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/tex-chtml.js"></script>
<style type="text/css">.CtxtMenu_InfoClose {  top:.2em; right:.2em;}
.CtxtMenu_InfoContent {  overflow:auto; text-align:left; font-size:80%;  padding:.4em .6em; border:1px inset; margin:1em 0px;  max-height:20em; max-width:30em; background-color:#EEEEEE;  white-space:normal;}
.CtxtMenu_Info.CtxtMenu_MousePost {outline:none;}
.CtxtMenu_Info {  position:fixed; left:50%; width:auto; text-align:center;  border:3px outset; padding:1em 2em; background-color:#DDDDDD;  color:black;  cursor:default; font-family:message-box; font-size:120%;  font-style:normal; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 15px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius:15px;               /* Safari and Chrome */  -moz-border-radius:15px;                  /* Firefox */  -khtml-border-radius:15px;                /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */  filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color="gray", Positive="true"); /* IE */}
</style><style type="text/css">.CtxtMenu_MenuClose {  position:absolute;  cursor:pointer;  display:inline-block;  border:2px solid #AAA;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  font-family: "Courier New", Courier;  font-size:24px;  color:#F0F0F0}
.CtxtMenu_MenuClose span {  display:block; background-color:#AAA; border:1.5px solid;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  line-height:0;  padding:8px 0 6px     /* may need to be browser-specific */}
.CtxtMenu_MenuClose:hover {  color:white!important;  border:2px solid #CCC!important}
.CtxtMenu_MenuClose:hover span {  background-color:#CCC!important}
.CtxtMenu_MenuClose:hover:focus {  outline:none}
</style><style type="text/css">.CtxtMenu_Menu {  position:absolute;  background-color:white;  color:black;  width:auto; padding:5px 0px;  border:1px solid #CCCCCC; margin:0; cursor:default;  font: menu; text-align:left; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 5px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius: 5px;             /* Safari and Chrome */  -moz-border-radius: 5px;                /* Firefox */  -khtml-border-radius: 5px;              /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */}
.CtxtMenu_MenuItem {  padding: 1px 2em;  background:transparent;}
.CtxtMenu_MenuArrow {  position:absolute; right:.5em; padding-top:.25em; color:#666666;  font-family: null; font-size: .75em}
.CtxtMenu_MenuActive .CtxtMenu_MenuArrow {color:white}
.CtxtMenu_MenuArrow.CtxtMenu_RTL {left:.5em; right:auto}
.CtxtMenu_MenuCheck {  position:absolute; left:.7em;  font-family: null}
.CtxtMenu_MenuCheck.CtxtMenu_RTL { right:.7em; left:auto }
.CtxtMenu_MenuRadioCheck {  position:absolute; left: .7em;}
.CtxtMenu_MenuRadioCheck.CtxtMenu_RTL {  right: .7em; left:auto}
.CtxtMenu_MenuInputBox {  padding-left: 1em; right:.5em; color:#666666;  font-family: null;}
.CtxtMenu_MenuInputBox.CtxtMenu_RTL {  left: .1em;}
.CtxtMenu_MenuComboBox {  left:.1em; padding-bottom:.5em;}
.CtxtMenu_MenuSlider {  left: .1em;}
.CtxtMenu_SliderValue {  position:absolute; right:.1em; padding-top:.25em; color:#333333;  font-size: .75em}
.CtxtMenu_SliderBar {  outline: none; background: #d3d3d3}
.CtxtMenu_MenuLabel {  padding: 1px 2em 3px 1.33em;  font-style:italic}
.CtxtMenu_MenuRule {  border-top: 1px solid #DDDDDD;  margin: 4px 3px;}
.CtxtMenu_MenuDisabled {  color:GrayText}
.CtxtMenu_MenuActive {  background-color: #606872;  color: white;}
.CtxtMenu_MenuDisabled:focus {  background-color: #E8E8E8}
.CtxtMenu_MenuLabel:focus {  background-color: #E8E8E8}
.CtxtMenu_ContextMenu:focus {  outline:none}
.CtxtMenu_ContextMenu .CtxtMenu_MenuItem:focus {  outline:none}
.CtxtMenu_SelectionMenu {  position:relative; float:left;  border-bottom: none; -webkit-box-shadow:none; -webkit-border-radius:0px; }
.CtxtMenu_SelectionItem {  padding-right: 1em;}
.CtxtMenu_Selection {  right: 40%; width:50%; }
.CtxtMenu_SelectionBox {  padding: 0em; max-height:20em; max-width: none;  background-color:#FFFFFF;}
.CtxtMenu_SelectionDivider {  clear: both; border-top: 2px solid #000000;}
.CtxtMenu_Menu .CtxtMenu_MenuClose {  top:-10px; left:-10px}
</style><style id="MJX-CHTML-styles">
mjx-container[jax="CHTML"] {
  line-height: 0;
}

mjx-container [space="1"] {
  margin-left: .111em;
}

mjx-container [space="2"] {
  margin-left: .167em;
}

mjx-container [space="3"] {
  margin-left: .222em;
}

mjx-container [space="4"] {
  margin-left: .278em;
}

mjx-container [space="5"] {
  margin-left: .333em;
}

mjx-container [rspace="1"] {
  margin-right: .111em;
}

mjx-container [rspace="2"] {
  margin-right: .167em;
}

mjx-container [rspace="3"] {
  margin-right: .222em;
}

mjx-container [rspace="4"] {
  margin-right: .278em;
}

mjx-container [rspace="5"] {
  margin-right: .333em;
}

mjx-container [size="s"] {
  font-size: 70.7%;
}

mjx-container [size="ss"] {
  font-size: 50%;
}

mjx-container [size="Tn"] {
  font-size: 60%;
}

mjx-container [size="sm"] {
  font-size: 85%;
}

mjx-container [size="lg"] {
  font-size: 120%;
}

mjx-container [size="Lg"] {
  font-size: 144%;
}

mjx-container [size="LG"] {
  font-size: 173%;
}

mjx-container [size="hg"] {
  font-size: 207%;
}

mjx-container [size="HG"] {
  font-size: 249%;
}

mjx-container [width="full"] {
  width: 100%;
}

mjx-box {
  display: inline-block;
}

mjx-block {
  display: block;
}

mjx-itable {
  display: inline-table;
}

mjx-row {
  display: table-row;
}

mjx-row > * {
  display: table-cell;
}

mjx-mtext {
  display: inline-block;
}

mjx-mstyle {
  display: inline-block;
}

mjx-merror {
  display: inline-block;
  color: red;
  background-color: yellow;
}

mjx-mphantom {
  visibility: hidden;
}

_::-webkit-full-page-media, _:future, :root mjx-container {
  will-change: opacity;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-c::before {
  display: block;
  width: 0;
}

.MJX-TEX {
  font-family: MJXZERO, MJXTEX;
}

.TEX-B {
  font-family: MJXZERO, MJXTEX-B;
}

.TEX-I {
  font-family: MJXZERO, MJXTEX-I;
}

.TEX-MI {
  font-family: MJXZERO, MJXTEX-MI;
}

.TEX-BI {
  font-family: MJXZERO, MJXTEX-BI;
}

.TEX-S1 {
  font-family: MJXZERO, MJXTEX-S1;
}

.TEX-S2 {
  font-family: MJXZERO, MJXTEX-S2;
}

.TEX-S3 {
  font-family: MJXZERO, MJXTEX-S3;
}

.TEX-S4 {
  font-family: MJXZERO, MJXTEX-S4;
}

.TEX-A {
  font-family: MJXZERO, MJXTEX-A;
}

.TEX-C {
  font-family: MJXZERO, MJXTEX-C;
}

.TEX-CB {
  font-family: MJXZERO, MJXTEX-CB;
}

.TEX-FR {
  font-family: MJXZERO, MJXTEX-FR;
}

.TEX-FRB {
  font-family: MJXZERO, MJXTEX-FRB;
}

.TEX-SS {
  font-family: MJXZERO, MJXTEX-SS;
}

.TEX-SSB {
  font-family: MJXZERO, MJXTEX-SSB;
}

.TEX-SSI {
  font-family: MJXZERO, MJXTEX-SSI;
}

.TEX-SC {
  font-family: MJXZERO, MJXTEX-SC;
}

.TEX-T {
  font-family: MJXZERO, MJXTEX-T;
}

.TEX-V {
  font-family: MJXZERO, MJXTEX-V;
}

.TEX-VB {
  font-family: MJXZERO, MJXTEX-VB;
}

mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c {
  font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A ! important;
}

@font-face /* 0 */ {
  font-family: MJXZERO;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff");
}

@font-face /* 1 */ {
  font-family: MJXTEX;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff");
}

@font-face /* 2 */ {
  font-family: MJXTEX-B;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff");
}

@font-face /* 3 */ {
  font-family: MJXTEX-I;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff");
}

@font-face /* 4 */ {
  font-family: MJXTEX-MI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff");
}

@font-face /* 5 */ {
  font-family: MJXTEX-BI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff");
}

@font-face /* 6 */ {
  font-family: MJXTEX-S1;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff");
}

@font-face /* 7 */ {
  font-family: MJXTEX-S2;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff");
}

@font-face /* 8 */ {
  font-family: MJXTEX-S3;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff");
}

@font-face /* 9 */ {
  font-family: MJXTEX-S4;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff");
}

@font-face /* 10 */ {
  font-family: MJXTEX-A;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff");
}

@font-face /* 11 */ {
  font-family: MJXTEX-C;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff");
}

@font-face /* 12 */ {
  font-family: MJXTEX-CB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff");
}

@font-face /* 13 */ {
  font-family: MJXTEX-FR;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff");
}

@font-face /* 14 */ {
  font-family: MJXTEX-FRB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff");
}

@font-face /* 15 */ {
  font-family: MJXTEX-SS;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff");
}

@font-face /* 16 */ {
  font-family: MJXTEX-SSB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff");
}

@font-face /* 17 */ {
  font-family: MJXTEX-SSI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff");
}

@font-face /* 18 */ {
  font-family: MJXTEX-SC;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff");
}

@font-face /* 19 */ {
  font-family: MJXTEX-T;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff");
}

@font-face /* 20 */ {
  font-family: MJXTEX-V;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff");
}

@font-face /* 21 */ {
  font-family: MJXTEX-VB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff");
}
</style></head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="https://jonathanbgn.com/">Jonathan Bgn</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="https://jonathanbgn.com/projects.html">Projects</a></div>
      </nav></div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope="" itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Simple Audio Augmentation with PyTorch</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2021-08-30T12:00:00+00:00" itemprop="datePublished">Aug 30, 2021
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>No matter if you are training a model for automatic speech recognition or something more esoteric like <a href="https://www.kaggle.com/c/birdsong-recognition">recognizing birds from sound</a>, you could benefit a lot from audio data augmentation. The idea is simple: <strong>by
 applying random transformations to your training examples, you can 
generate new examples for free and make your training dataset bigger.</strong></p>

<p>In computer vision, for example, images can be randomly cropped, 
rotated… colors can be distorted, and so on. Of course, transformations 
should not be so destructive as to change the label of the example. If 
the label for one image is ‘dog’, the resulting image after 
transformations should still display a recognizable dog (you don’t want a
 picture of a pink tail).</p>

<p><img src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/butterfly_augmentation.png" alt="Data augmentation examples for an image" style="max-width: 80%; margin: auto; display: block;"></p>

<p><em>Data augmentation for images (<a href="https://www.researchgate.net/publication/319413978_Data_augmentation-assisted_deep_learning_of_hand-drawn_partially_colored_sketches_for_visual_search">Source</a>)</em></p>

<p>Augmenting your dataset can often provide much more benefits than 
just tweaking your model architecture or hyperparameters. Andrej 
Karpathy, Tesla’s AI chief, goes so far as calling <a href="http://karpathy.github.io/2019/04/25/recipe/#4-regularize">data augmentation the best thing you can do to prevent overfitting</a> (excluding getting new real data), before other regularization techniques such as dropout, weight decay, early stopping…</p>

<hr>

<h2 id="three-easy-to-apply-audio-transformations">Three easy-to-apply audio transformations</h2>

<p>Data augmentation does not have to be difficult, and from my own 
experience, the simplest techniques usually work better (on top of being
 easier to debug). In this tutorial, we will use PyTorch’s <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a> library to implement some of these techniques in only a few lines of code.</p>

<p>For demo purposes, we will use a ~30s speech sample downloaded from the <a href="http://www.voiptroubleshooter.com/open_speech/">Open Speech Repository</a>. First, let’s load the audio data along with the sample rate of the recording:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">torchaudio</span>

<span class="n">audio_data</span><span class="p">,</span> <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'OSR_us_000_0010_8k.wav'</span><span class="p">)</span></code></pre></figure>

<p><img src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/original.png" alt="Sample audio waveform"></p>

<audio controls="controls" style="margin: auto; display: block; margin-bottom: 30px;">
 <source src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/OSR_us_000_0010_8k.wav" type="audio/mpeg">
 Your browser does not support the audio element.
</audio>

<h3 id="1-random-clipping">1. Random clipping</h3>

<p>A very simple yet effective technique I use whenever training 
audio/speech models is taking a random segment of the audio clip. Not 
only this makes the model much more robust to time-shifting, it is also a
 neat way to batch audio files with different durations and prevent the 
use of padding which can create its own problems. If you don’t care 
about having the same length for each audio file, you could also apply 
PyTorch’s included Voice Activity Detector to trim silences at the 
beginning and end of the clipped segment.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>

<span class="k">class</span> <span class="nc">RandomClip</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">clip_length</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">clip_length</span> <span class="o">=</span> <span class="n">clip_length</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">vad</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="n">Vad</span><span class="p">(</span>
            <span class="n">sample_rate</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">trigger_level</span><span class="o">=</span><span class="mf">7.0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_data</span><span class="p">):</span>
        <span class="n">audio_length</span> <span class="o">=</span> <span class="n">audio_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">audio_length</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">clip_length</span><span class="p">:</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">audio_length</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">clip_length</span><span class="p">)</span>
            <span class="n">audio_data</span> <span class="o">=</span> <span class="n">audio_data</span><span class="p">[</span><span class="n">offset</span><span class="p">:(</span><span class="n">offset</span><span class="o">+</span><span class="bp">self</span><span class="p">.</span><span class="n">clip_length</span><span class="p">)]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">vad</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span> <span class="c1"># remove silences at the beggining/end
</span>
<span class="n">clip_transform</span> <span class="o">=</span> <span class="n">RandomClip</span><span class="p">(</span><span class="n">sample_rate</span><span class="p">,</span> <span class="mi">64000</span><span class="p">)</span> <span class="c1"># 8 seconds clip
</span><span class="n">transformed_audio</span> <span class="o">=</span> <span class="n">clip_transform</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span></code></pre></figure>

<p><img src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/clipped.png" alt="Random clipping"></p>

<audio controls="controls" style="margin: auto; display: block; margin-bottom: 30px;">
 <source src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/clipped.wav" type="audio/mpeg">
 Your browser does not support the audio element.
</audio>

<p>Of course, you should make sure that clipping the audio won’t change 
the label. For tasks like speaker or language identification, this 
should not be a problem. But if you are training a speech recognition 
system, for instance, make sure that you also clip the transcription 
accordingly to preserve the integrity of the data.</p>

<h3 id="2-speed-perturbation">2. Speed perturbation</h3>

<p>Torchaudio lets you apply all sorts of effects on audio such as 
changing the pitch, applying low/high pass filter, adding reverberation,
 and so on (<a href="http://sox.sourceforge.net/sox.html">full list here</a>). One particularly effective technique for speech-based applications, however, is to just change the speed of the audio signal.</p>

<p>Indeed, it has been shown that producing two augmented versions of the original dataset with speed factors of 0.9 and 1.1 could <a href="https://danielpovey.com/files/2015_interspeech_augmentation.pdf">significantly improve speech recognition</a>, more than other more complicated methods based on vocal tract lengths.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">random</span>

<span class="k">class</span> <span class="nc">RandomSpeedChange</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_data</span><span class="p">):</span>
        <span class="n">speed_factor</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">([</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">speed_factor</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span> <span class="c1"># no change
</span>            <span class="k">return</span> <span class="n">audio_data</span>

        <span class="c1"># change speed and resample to original rate:
</span>        <span class="n">sox_effects</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span><span class="s">"speed"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">speed_factor</span><span class="p">)],</span>
            <span class="p">[</span><span class="s">"rate"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">)],</span>
        <span class="p">]</span>
        <span class="n">transformed_audio</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">sox_effects</span><span class="p">.</span><span class="n">apply_effects_tensor</span><span class="p">(</span>
            <span class="n">audio_data</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">sox_effects</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">transformed_audio</span>
 
<span class="n">speed_transform</span> <span class="o">=</span> <span class="n">RandomSpeedChange</span><span class="p">(</span><span class="n">sample_rate</span><span class="p">)</span>
<span class="n">transformed_audio</span> <span class="o">=</span> <span class="n">speed_transform</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span></code></pre></figure>

<p>The following is the original audio file with speed increased by a factor of 1.1.</p>

<p><img src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/faster.png" alt="Speed increased by x1.1"></p>

<audio controls="controls" style="margin: auto; display: block; margin-bottom: 30px;">
 <source src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/faster.wav" type="audio/mpeg">
 Your browser does not support the audio element.
</audio>

<h3 id="3-background-noise">3. Background noise</h3>

<p>We could just add auto-generated noises like <a href="https://en.wikipedia.org/wiki/White_noise">white noise</a>
 in the background, but adding real noises and sounds can increase a lot
 the robustness of models. Especially important is to have a large 
enough library of noises so that the model very rarely sees the same 
noise twice during training. Fortunately, there exists tons of free 
sound databases online. I strongly recommend <a href="http://www.openslr.org/17/">MUSAN</a>, a large 11GB collection of music, speech, and noise recordings.</p>

<p>The following transform will pick a random noise file from a given 
folder and will apply it to the original audio file. For added 
diversity, it will also choose a random <a href="https://en.wikipedia.org/wiki/Signal-to-noise_ratio">signal-to-noise ratio</a> (from a given range) to apply noises at a different volume compared to the original signal.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">RandomBackgroundNoise</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">noise_dir</span><span class="p">,</span> <span class="n">min_snr_db</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_snr_db</span><span class="o">=</span><span class="mi">15</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">min_snr_db</span> <span class="o">=</span> <span class="n">min_snr_db</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_snr_db</span> <span class="o">=</span> <span class="n">max_snr_db</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">noise_dir</span><span class="p">):</span>
            <span class="k">raise</span> <span class="nb">IOError</span><span class="p">(</span><span class="sa">f</span><span class="s">'Noise directory `</span><span class="si">{</span><span class="n">noise_dir</span><span class="si">}</span><span class="s">` does not exist'</span><span class="p">)</span>
        <span class="c1"># find all WAV files including in sub-folders:
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">noise_files_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pathlib</span><span class="p">.</span><span class="n">Path</span><span class="p">(</span><span class="n">noise_dir</span><span class="p">).</span><span class="n">glob</span><span class="p">(</span><span class="s">'**/*.wav'</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">noise_files_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">IOError</span><span class="p">(</span><span class="sa">f</span><span class="s">'No .wav file found in the noise directory `</span><span class="si">{</span><span class="n">noise_dir</span><span class="si">}</span><span class="s">`'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_data</span><span class="p">):</span>
        <span class="n">random_noise_file</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">noise_files_list</span><span class="p">)</span>
        <span class="n">effects</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span><span class="s">'remix'</span><span class="p">,</span> <span class="s">'1'</span><span class="p">],</span> <span class="c1"># convert to mono
</span>            <span class="p">[</span><span class="s">'rate'</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">)],</span> <span class="c1"># resample
</span>        <span class="p">]</span>
        <span class="n">noise</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">sox_effects</span><span class="p">.</span><span class="n">apply_effects_file</span><span class="p">(</span><span class="n">random_noise_file</span><span class="p">,</span> <span class="n">effects</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">audio_length</span> <span class="o">=</span> <span class="n">audio_data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">noise_length</span> <span class="o">=</span> <span class="n">noise</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">noise_length</span> <span class="o">&gt;</span> <span class="n">audio_length</span><span class="p">:</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_length</span><span class="o">-</span><span class="n">audio_length</span><span class="p">)</span>
            <span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span><span class="p">[...,</span> <span class="n">offset</span><span class="p">:</span><span class="n">offset</span><span class="o">+</span><span class="n">audio_length</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">noise_length</span> <span class="o">&lt;</span> <span class="n">audio_length</span><span class="p">:</span>
            <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">noise</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">noise</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">audio_length</span><span class="o">-</span><span class="n">noise_length</span><span class="p">))],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">snr_db</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">min_snr_db</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_snr_db</span><span class="p">)</span>
        <span class="n">snr</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">snr_db</span> <span class="o">/</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">audio_power</span> <span class="o">=</span> <span class="n">audio_data</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">noise_power</span> <span class="o">=</span> <span class="n">noise</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">snr</span> <span class="o">*</span> <span class="n">noise_power</span> <span class="o">/</span> <span class="n">audio_power</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">scale</span> <span class="o">*</span> <span class="n">audio_data</span> <span class="o">+</span> <span class="n">noise</span> <span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
 
<span class="n">noise_transform</span> <span class="o">=</span> <span class="n">RandomBackgroundNoise</span><span class="p">(</span><span class="n">sample_rate</span><span class="p">,</span> <span class="s">'./noises_directory'</span><span class="p">)</span>
<span class="n">transformed_audio</span> <span class="o">=</span> <span class="n">noise_transform</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span></code></pre></figure>

<p>The following audio example is the original file with a randomly added sound of a crowd in the background.</p>

<p><img src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/background_noise.png" alt="Crowd noise in the background"></p>

<audio controls="controls" style="margin: auto; display: block; margin-bottom: 30px;">
 <source src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/background_noise.wav" type="audio/mpeg">
 Your browser does not support the audio element.
</audio>

<hr>

<h2 id="combine-transformations">Combine transformations</h2>

<p>The beauty of PyTorch’s transforms design pattern is that you can 
easily combine them. From this simple set of three transformations, we 
could generate an infinite number of diverse-enough examples by applying
 transformations on the fly during training.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">ComposeTransform</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_data</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">audio_data</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">audio_data</span>

<span class="n">compose_transform</span> <span class="o">=</span> <span class="n">ComposeTransform</span><span class="p">([</span>
    <span class="n">RandomClip</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">64000</span><span class="p">),</span>
    <span class="n">RandomSpeedChange</span><span class="p">(</span><span class="n">sample_rate</span><span class="p">),</span>
    <span class="n">RandomBackgroundNoise</span><span class="p">(</span><span class="n">sample_rate</span><span class="p">,</span> <span class="s">'./noises_directory'</span><span class="p">)])</span>

<span class="n">transformed_audio</span> <span class="o">=</span> <span class="n">compose_transform</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span></code></pre></figure>

<p>The following audio examples were all generated from the same original audio file.</p>

<audio controls="controls">
 <source src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/composed1.wav" type="audio/mpeg">
 Your browser does not support the audio element.
</audio>

<audio controls="controls">
 <source src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/composed2.wav" type="audio/mpeg">
 Your browser does not support the audio element.
</audio>

<audio controls="controls">
 <source src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/composed3.wav" type="audio/mpeg">
 Your browser does not support the audio element.
</audio>

<audio controls="controls">
 <source src="Simple%20Audio%20Augmentation%20with%20PyTorch%20Jonathan%20Bgn_files/composed4.wav" type="audio/mpeg">
 Your browser does not support the audio element.
</audio>

<hr>

<h2 id="more-advanced-augmentation">More advanced augmentation</h2>

<p>In my experience, these simple techniques should already bring you quite far. If you want to go further, there exists <a href="https://github.com/iver56/audiomentations">external</a> <a href="https://github.com/asteroid-team/torch-audiomentations">libraries</a>
 to apply more sophisticated effects, although they might not translate 
into better model performance and generalization. The official <a href="https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html#simulating-room-reverbration">torchaudio tutorial</a> also describes an interesting method to apply room reverberation from a dataset of <a href="https://www.openslr.org/28/">room impulse responses</a> (someone clapping hands in an empty room). Keep in mind that you need clean audio recording for this to work properly.</p>

<p>It is also possible to apply data augmentation techniques directly on
 the features computed from the audio, rather than on the raw audio 
itself. <a href="https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html">SpecAugment</a>
 for example apply transformations directly on the spectrogram of the 
audio signal, such as time or frequency masking. Torchaudio also comes 
with a convenient <a href="https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html#specaugment">SpecAugment implementation</a>.</p>

<p>The future is bright! As the field of machine learning is moving more and more towards a <a href="https://www.deeplearning.ai/wp-content/uploads/2021/06/MLOps-From-Model-centric-to-Data-centric-AI.pdf">data-centric approach</a>
 rather than model-centric, new techniques and resources will likely 
appear in the near future to help with setting up better and faster data
 augmentation pipelines.</p>


  </div><a class="u-url" href="https://jonathanbgn.com/2021/08/30/audio-augmentation.html" hidden=""></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Jonathan Boigne</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1"><ul class="social-media-list"><li><a href="https://www.linkedin.com/in/jonathan-boigne"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">jonathan-boigne</span></a></li><li><a href="https://github.com/jonathanbgn"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jonathanbgn</span></a></li><li><a href="https://www.twitter.com/jonathanbgn"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jonathanbgn</span></a></li></ul>
<ul class="contact-list"><li><a class="u-email" href="mailto:hello@jonathanbgn.com">hello@jonathanbgn.com</a></li></ul>

      </div>

      <div class="footer-col footer-col-2">
      </div>

      <div class="footer-col footer-col-3">
        <p>Building stuff with machine learning and natural language processing.</p>
      </div>
    </div>

  </div>

</footer>



<nordpass-passkeys></nordpass-passkeys></body></html>